{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPn+WA9vuku0YV4qkjOO5yi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":[],"metadata":{"id":"ROUJBZyh-P5A"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"id":"yCenuS7gAREL","executionInfo":{"status":"ok","timestamp":1733102797317,"user_tz":300,"elapsed":311,"user":{"displayName":"Anisha Parida","userId":"13539468926741323766"}}},"outputs":[],"source":["from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","source":[],"metadata":{"id":"qF3Jwni890qw"}},{"cell_type":"code","source":["train_data = datasets.MNIST(\n","    root = 'data',\n","    train = True,\n","    transform = ToTensor(),\n","    download = True,\n",")\n","\n","test_data = datasets.MNIST(\n","    root = 'data',\n","    train = False,\n","    transform = ToTensor()\n",")"],"metadata":{"id":"aRq9jIu391SS","executionInfo":{"status":"ok","timestamp":1733102801790,"user_tz":300,"elapsed":136,"user":{"displayName":"Anisha Parida","userId":"13539468926741323766"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["train_data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jWAxmlzg-iGn","executionInfo":{"status":"ok","timestamp":1733102824902,"user_tz":300,"elapsed":242,"user":{"displayName":"Anisha Parida","userId":"13539468926741323766"}},"outputId":"72d1b244-7d8b-4ee6-d1f1-7a5917df7370"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset MNIST\n","    Number of datapoints: 60000\n","    Root location: data\n","    Split: Train\n","    StandardTransform\n","Transform: ToTensor()"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["test_data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ojIglbnc-njH","executionInfo":{"status":"ok","timestamp":1733102839438,"user_tz":300,"elapsed":111,"user":{"displayName":"Anisha Parida","userId":"13539468926741323766"}},"outputId":"ea3a938d-f674-4fe8-c485-53c7c5d23d4c"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset MNIST\n","    Number of datapoints: 10000\n","    Root location: data\n","    Split: Test\n","    StandardTransform\n","Transform: ToTensor()"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["train_data.data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WB8tCs1V-q-q","executionInfo":{"status":"ok","timestamp":1733102865227,"user_tz":300,"elapsed":100,"user":{"displayName":"Anisha Parida","userId":"13539468926741323766"}},"outputId":"1c7ad91d-750f-447a-efcb-fe14e82a02b1"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0]],\n","\n","        [[0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0]],\n","\n","        [[0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0]],\n","\n","        ...,\n","\n","        [[0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0]],\n","\n","        [[0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0]],\n","\n","        [[0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["train_data.data.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3uZGhxGU-21k","executionInfo":{"status":"ok","timestamp":1733102931125,"user_tz":300,"elapsed":127,"user":{"displayName":"Anisha Parida","userId":"13539468926741323766"}},"outputId":"2c75e965-130d-4159-dc76-bf340a88ee97"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([60000, 28, 28])"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["test_data.data.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"50zeERSd_FNK","executionInfo":{"status":"ok","timestamp":1733102974374,"user_tz":300,"elapsed":94,"user":{"displayName":"Anisha Parida","userId":"13539468926741323766"}},"outputId":"24721a6f-46dc-4352-a661-09d475159224"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([10000, 28, 28])"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["train_data.targets.size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HivJmcnm_MP9","executionInfo":{"status":"ok","timestamp":1733103020467,"user_tz":300,"elapsed":408,"user":{"displayName":"Anisha Parida","userId":"13539468926741323766"}},"outputId":"1306fd9c-0c47-499f-9beb-207d0677e45e"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([60000])"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["train_data.targets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mYdfSm_f_XKD","executionInfo":{"status":"ok","timestamp":1733104517716,"user_tz":300,"elapsed":213,"user":{"displayName":"Anisha Parida","userId":"13539468926741323766"}},"outputId":"0a36e9bf-1db1-4b89-ffe8-aab8366f1320"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([5, 0, 4,  ..., 5, 6, 8])"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","\n","loaders = {\n","    'train' : DataLoader(train_data,\n","                                          batch_size=100,\n","                                          shuffle=True,\n","                                          num_workers=1),\n","\n","    'test'  : DataLoader(test_data, batch_size=100, shuffle=True, num_workers=1),\n","}\n"],"metadata":{"id":"P2WMmYz5FEr0","executionInfo":{"status":"ok","timestamp":1733104688048,"user_tz":300,"elapsed":147,"user":{"displayName":"Anisha Parida","userId":"13539468926741323766"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["loaders"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Do40fdoxFw4L","executionInfo":{"status":"ok","timestamp":1733104705629,"user_tz":300,"elapsed":188,"user":{"displayName":"Anisha Parida","userId":"13539468926741323766"}},"outputId":"f7501892-07c7-47f8-d682-2291f27d161e"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'train': <torch.utils.data.dataloader.DataLoader at 0x7f3cd3ee8dc0>,\n"," 'test': <torch.utils.data.dataloader.DataLoader at 0x7f3cd3ee8160>}"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","class CNN(nn.Module):\n","\n","  def __init__(self):\n","\n","    super(CNN, self).__init__()\n","\n","    self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n","    self.conv2 = nn.Conv2d(10,20, kernel_size=5)\n","\n","    self.conv2_drop = nn.Dropout2d()\n","    self.fc1 = nn.Linear(320, 50)\n","    self.fc2 = nn.Linear(50, 10)\n","\n","  def forward(self, x):\n","\n","    x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","    x= F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n","    x = x.view(-1, 320)\n","    x = F.relu(self.fc1(x))\n","    x = F.dropout(x, training=self.training)\n","    x = self.fc2(x)\n","\n","    return F.softmax(x)"],"metadata":{"id":"8QSgeg3FFylj","executionInfo":{"status":"ok","timestamp":1733166565201,"user_tz":300,"elapsed":4316,"user":{"displayName":"Anisha Parida","userId":"13539468926741323766"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","model = CNN().to(device)\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","loss_fn = nn.CrossEntropyLoss()\n","\n","\n","train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n","test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n","\n","loaders = {\n","    'train': DataLoader(train_dataset, batch_size=64, shuffle=True),\n","    'test': DataLoader(test_dataset, batch_size=1000, shuffle=False),\n","}\n","\n","def train(epoch):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(loaders['train']):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = loss_fn(output, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","        if batch_idx % 20 == 0:\n","            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders[\"train\"].dataset)} '\n","                  f'({100. * batch_idx / len(loaders[\"train\"]):.0f}%)]\\tLoss: {loss.item():.6f}')\n","\n","def test():\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in loaders['test']:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += loss_fn(output, target).item()\n","            pred = output.data.max(1, keepdim=True)[1]\n","            correct += pred.eq(target.data.view_as(pred)).sum().item()\n","    test_loss /= len(loaders['test'].dataset)\n","    print(f\"Test Set: Average Loss: {test_loss:.4f}, Accuracy: {correct}/{len(loaders['test'].dataset)} \"\n","          f\"({(100. * correct / len(loaders['test'].dataset)):.0f}%)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qnPwhBZtGpdQ","executionInfo":{"status":"ok","timestamp":1733169085378,"user_tz":300,"elapsed":14362,"user":{"displayName":"Anisha Parida","userId":"13539468926741323766"}},"outputId":"c9850353-0a92-44c2-e877-4ab221bc4bdd"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9.91M/9.91M [00:01<00:00, 5.79MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28.9k/28.9k [00:00<00:00, 153kB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1.65M/1.65M [00:01<00:00, 1.45MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4.54k/4.54k [00:00<00:00, 2.55MB/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"Yt5juWtn3Vlq"}},{"cell_type":"code","source":["for epoch in range(1, 11):\n","  train(epoch)\n","  test()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cdz6S3DO6Pe9","executionInfo":{"status":"ok","timestamp":1733169460683,"user_tz":300,"elapsed":316760,"user":{"displayName":"Anisha Parida","userId":"13539468926741323766"}},"outputId":"16ae0c61-596f-429e-b964-c6194ccc6354"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-1-521ba2b4a20a>:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return F.softmax(x)\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.304575\n","Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.296247\n","Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.170010\n","Train Epoch: 1 [3840/60000 (6%)]\tLoss: 1.955602\n","Train Epoch: 1 [5120/60000 (9%)]\tLoss: 1.929403\n","Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.920899\n","Train Epoch: 1 [7680/60000 (13%)]\tLoss: 1.824829\n","Train Epoch: 1 [8960/60000 (15%)]\tLoss: 1.773651\n","Train Epoch: 1 [10240/60000 (17%)]\tLoss: 1.782560\n","Train Epoch: 1 [11520/60000 (19%)]\tLoss: 1.737588\n","Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.766566\n","Train Epoch: 1 [14080/60000 (23%)]\tLoss: 1.783307\n","Train Epoch: 1 [15360/60000 (26%)]\tLoss: 1.686093\n","Train Epoch: 1 [16640/60000 (28%)]\tLoss: 1.745927\n","Train Epoch: 1 [17920/60000 (30%)]\tLoss: 1.746812\n","Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.678128\n","Train Epoch: 1 [20480/60000 (34%)]\tLoss: 1.674489\n","Train Epoch: 1 [21760/60000 (36%)]\tLoss: 1.672008\n","Train Epoch: 1 [23040/60000 (38%)]\tLoss: 1.696854\n","Train Epoch: 1 [24320/60000 (41%)]\tLoss: 1.652158\n","Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.630218\n","Train Epoch: 1 [26880/60000 (45%)]\tLoss: 1.646686\n","Train Epoch: 1 [28160/60000 (47%)]\tLoss: 1.662739\n","Train Epoch: 1 [29440/60000 (49%)]\tLoss: 1.664991\n","Train Epoch: 1 [30720/60000 (51%)]\tLoss: 1.730443\n","Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.590493\n","Train Epoch: 1 [33280/60000 (55%)]\tLoss: 1.607276\n","Train Epoch: 1 [34560/60000 (58%)]\tLoss: 1.684284\n","Train Epoch: 1 [35840/60000 (60%)]\tLoss: 1.636295\n","Train Epoch: 1 [37120/60000 (62%)]\tLoss: 1.673041\n","Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1.588638\n","Train Epoch: 1 [39680/60000 (66%)]\tLoss: 1.612173\n","Train Epoch: 1 [40960/60000 (68%)]\tLoss: 1.641317\n","Train Epoch: 1 [42240/60000 (70%)]\tLoss: 1.626323\n","Train Epoch: 1 [43520/60000 (72%)]\tLoss: 1.571687\n","Train Epoch: 1 [44800/60000 (75%)]\tLoss: 1.581016\n","Train Epoch: 1 [46080/60000 (77%)]\tLoss: 1.677559\n","Train Epoch: 1 [47360/60000 (79%)]\tLoss: 1.571621\n","Train Epoch: 1 [48640/60000 (81%)]\tLoss: 1.602009\n","Train Epoch: 1 [49920/60000 (83%)]\tLoss: 1.652736\n","Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1.572255\n","Train Epoch: 1 [52480/60000 (87%)]\tLoss: 1.581910\n","Train Epoch: 1 [53760/60000 (90%)]\tLoss: 1.618585\n","Train Epoch: 1 [55040/60000 (92%)]\tLoss: 1.609735\n","Train Epoch: 1 [56320/60000 (94%)]\tLoss: 1.549971\n","Train Epoch: 1 [57600/60000 (96%)]\tLoss: 1.583805\n","Train Epoch: 1 [58880/60000 (98%)]\tLoss: 1.654179\n","Test Set: Average Loss: 0.0015, Accuracy: 9428/10000 (94%)\n","Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.570337\n","Train Epoch: 2 [1280/60000 (2%)]\tLoss: 1.607247\n","Train Epoch: 2 [2560/60000 (4%)]\tLoss: 1.617391\n","Train Epoch: 2 [3840/60000 (6%)]\tLoss: 1.545929\n","Train Epoch: 2 [5120/60000 (9%)]\tLoss: 1.620976\n","Train Epoch: 2 [6400/60000 (11%)]\tLoss: 1.549481\n","Train Epoch: 2 [7680/60000 (13%)]\tLoss: 1.597082\n","Train Epoch: 2 [8960/60000 (15%)]\tLoss: 1.590169\n","Train Epoch: 2 [10240/60000 (17%)]\tLoss: 1.631967\n","Train Epoch: 2 [11520/60000 (19%)]\tLoss: 1.596284\n","Train Epoch: 2 [12800/60000 (21%)]\tLoss: 1.587433\n","Train Epoch: 2 [14080/60000 (23%)]\tLoss: 1.577845\n","Train Epoch: 2 [15360/60000 (26%)]\tLoss: 1.548042\n","Train Epoch: 2 [16640/60000 (28%)]\tLoss: 1.587855\n","Train Epoch: 2 [17920/60000 (30%)]\tLoss: 1.519337\n","Train Epoch: 2 [19200/60000 (32%)]\tLoss: 1.552789\n","Train Epoch: 2 [20480/60000 (34%)]\tLoss: 1.534566\n","Train Epoch: 2 [21760/60000 (36%)]\tLoss: 1.639805\n","Train Epoch: 2 [23040/60000 (38%)]\tLoss: 1.513349\n","Train Epoch: 2 [24320/60000 (41%)]\tLoss: 1.593858\n","Train Epoch: 2 [25600/60000 (43%)]\tLoss: 1.540872\n","Train Epoch: 2 [26880/60000 (45%)]\tLoss: 1.531907\n","Train Epoch: 2 [28160/60000 (47%)]\tLoss: 1.567718\n","Train Epoch: 2 [29440/60000 (49%)]\tLoss: 1.547302\n","Train Epoch: 2 [30720/60000 (51%)]\tLoss: 1.554475\n","Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1.589014\n","Train Epoch: 2 [33280/60000 (55%)]\tLoss: 1.555422\n","Train Epoch: 2 [34560/60000 (58%)]\tLoss: 1.564837\n","Train Epoch: 2 [35840/60000 (60%)]\tLoss: 1.599011\n","Train Epoch: 2 [37120/60000 (62%)]\tLoss: 1.612679\n","Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.627149\n","Train Epoch: 2 [39680/60000 (66%)]\tLoss: 1.579950\n","Train Epoch: 2 [40960/60000 (68%)]\tLoss: 1.588555\n","Train Epoch: 2 [42240/60000 (70%)]\tLoss: 1.564796\n","Train Epoch: 2 [43520/60000 (72%)]\tLoss: 1.475412\n","Train Epoch: 2 [44800/60000 (75%)]\tLoss: 1.565866\n","Train Epoch: 2 [46080/60000 (77%)]\tLoss: 1.501989\n","Train Epoch: 2 [47360/60000 (79%)]\tLoss: 1.573694\n","Train Epoch: 2 [48640/60000 (81%)]\tLoss: 1.513864\n","Train Epoch: 2 [49920/60000 (83%)]\tLoss: 1.583772\n","Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1.571056\n","Train Epoch: 2 [52480/60000 (87%)]\tLoss: 1.549027\n","Train Epoch: 2 [53760/60000 (90%)]\tLoss: 1.549166\n","Train Epoch: 2 [55040/60000 (92%)]\tLoss: 1.607144\n","Train Epoch: 2 [56320/60000 (94%)]\tLoss: 1.597124\n","Train Epoch: 2 [57600/60000 (96%)]\tLoss: 1.565670\n","Train Epoch: 2 [58880/60000 (98%)]\tLoss: 1.579915\n","Test Set: Average Loss: 0.0015, Accuracy: 9558/10000 (96%)\n","Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.561811\n","Train Epoch: 3 [1280/60000 (2%)]\tLoss: 1.558291\n","Train Epoch: 3 [2560/60000 (4%)]\tLoss: 1.565712\n","Train Epoch: 3 [3840/60000 (6%)]\tLoss: 1.540106\n","Train Epoch: 3 [5120/60000 (9%)]\tLoss: 1.583208\n","Train Epoch: 3 [6400/60000 (11%)]\tLoss: 1.586033\n","Train Epoch: 3 [7680/60000 (13%)]\tLoss: 1.533397\n","Train Epoch: 3 [8960/60000 (15%)]\tLoss: 1.586526\n","Train Epoch: 3 [10240/60000 (17%)]\tLoss: 1.578924\n","Train Epoch: 3 [11520/60000 (19%)]\tLoss: 1.594080\n","Train Epoch: 3 [12800/60000 (21%)]\tLoss: 1.532552\n","Train Epoch: 3 [14080/60000 (23%)]\tLoss: 1.550008\n","Train Epoch: 3 [15360/60000 (26%)]\tLoss: 1.601935\n","Train Epoch: 3 [16640/60000 (28%)]\tLoss: 1.578827\n","Train Epoch: 3 [17920/60000 (30%)]\tLoss: 1.601614\n","Train Epoch: 3 [19200/60000 (32%)]\tLoss: 1.543517\n","Train Epoch: 3 [20480/60000 (34%)]\tLoss: 1.563007\n","Train Epoch: 3 [21760/60000 (36%)]\tLoss: 1.549664\n","Train Epoch: 3 [23040/60000 (38%)]\tLoss: 1.524063\n","Train Epoch: 3 [24320/60000 (41%)]\tLoss: 1.563984\n","Train Epoch: 3 [25600/60000 (43%)]\tLoss: 1.507105\n","Train Epoch: 3 [26880/60000 (45%)]\tLoss: 1.584024\n","Train Epoch: 3 [28160/60000 (47%)]\tLoss: 1.576692\n","Train Epoch: 3 [29440/60000 (49%)]\tLoss: 1.553544\n","Train Epoch: 3 [30720/60000 (51%)]\tLoss: 1.563720\n","Train Epoch: 3 [32000/60000 (53%)]\tLoss: 1.533916\n","Train Epoch: 3 [33280/60000 (55%)]\tLoss: 1.569705\n","Train Epoch: 3 [34560/60000 (58%)]\tLoss: 1.551983\n","Train Epoch: 3 [35840/60000 (60%)]\tLoss: 1.544408\n","Train Epoch: 3 [37120/60000 (62%)]\tLoss: 1.501658\n","Train Epoch: 3 [38400/60000 (64%)]\tLoss: 1.539328\n","Train Epoch: 3 [39680/60000 (66%)]\tLoss: 1.503474\n","Train Epoch: 3 [40960/60000 (68%)]\tLoss: 1.490942\n","Train Epoch: 3 [42240/60000 (70%)]\tLoss: 1.570291\n","Train Epoch: 3 [43520/60000 (72%)]\tLoss: 1.606086\n","Train Epoch: 3 [44800/60000 (75%)]\tLoss: 1.653078\n","Train Epoch: 3 [46080/60000 (77%)]\tLoss: 1.588593\n","Train Epoch: 3 [47360/60000 (79%)]\tLoss: 1.571223\n","Train Epoch: 3 [48640/60000 (81%)]\tLoss: 1.598962\n","Train Epoch: 3 [49920/60000 (83%)]\tLoss: 1.625937\n","Train Epoch: 3 [51200/60000 (85%)]\tLoss: 1.514530\n","Train Epoch: 3 [52480/60000 (87%)]\tLoss: 1.547578\n","Train Epoch: 3 [53760/60000 (90%)]\tLoss: 1.527893\n","Train Epoch: 3 [55040/60000 (92%)]\tLoss: 1.611089\n","Train Epoch: 3 [56320/60000 (94%)]\tLoss: 1.509425\n","Train Epoch: 3 [57600/60000 (96%)]\tLoss: 1.590295\n","Train Epoch: 3 [58880/60000 (98%)]\tLoss: 1.586132\n","Test Set: Average Loss: 0.0015, Accuracy: 9596/10000 (96%)\n","Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.573665\n","Train Epoch: 4 [1280/60000 (2%)]\tLoss: 1.563370\n","Train Epoch: 4 [2560/60000 (4%)]\tLoss: 1.506188\n","Train Epoch: 4 [3840/60000 (6%)]\tLoss: 1.498775\n","Train Epoch: 4 [5120/60000 (9%)]\tLoss: 1.537542\n","Train Epoch: 4 [6400/60000 (11%)]\tLoss: 1.532936\n","Train Epoch: 4 [7680/60000 (13%)]\tLoss: 1.556947\n","Train Epoch: 4 [8960/60000 (15%)]\tLoss: 1.529682\n","Train Epoch: 4 [10240/60000 (17%)]\tLoss: 1.526025\n","Train Epoch: 4 [11520/60000 (19%)]\tLoss: 1.567838\n","Train Epoch: 4 [12800/60000 (21%)]\tLoss: 1.528103\n","Train Epoch: 4 [14080/60000 (23%)]\tLoss: 1.521778\n","Train Epoch: 4 [15360/60000 (26%)]\tLoss: 1.543982\n","Train Epoch: 4 [16640/60000 (28%)]\tLoss: 1.536615\n","Train Epoch: 4 [17920/60000 (30%)]\tLoss: 1.491670\n","Train Epoch: 4 [19200/60000 (32%)]\tLoss: 1.565323\n","Train Epoch: 4 [20480/60000 (34%)]\tLoss: 1.487891\n","Train Epoch: 4 [21760/60000 (36%)]\tLoss: 1.499041\n","Train Epoch: 4 [23040/60000 (38%)]\tLoss: 1.533398\n","Train Epoch: 4 [24320/60000 (41%)]\tLoss: 1.544127\n","Train Epoch: 4 [25600/60000 (43%)]\tLoss: 1.522348\n","Train Epoch: 4 [26880/60000 (45%)]\tLoss: 1.517202\n","Train Epoch: 4 [28160/60000 (47%)]\tLoss: 1.533697\n","Train Epoch: 4 [29440/60000 (49%)]\tLoss: 1.544740\n","Train Epoch: 4 [30720/60000 (51%)]\tLoss: 1.591135\n","Train Epoch: 4 [32000/60000 (53%)]\tLoss: 1.525931\n","Train Epoch: 4 [33280/60000 (55%)]\tLoss: 1.517631\n","Train Epoch: 4 [34560/60000 (58%)]\tLoss: 1.539115\n","Train Epoch: 4 [35840/60000 (60%)]\tLoss: 1.594711\n","Train Epoch: 4 [37120/60000 (62%)]\tLoss: 1.553271\n","Train Epoch: 4 [38400/60000 (64%)]\tLoss: 1.544005\n","Train Epoch: 4 [39680/60000 (66%)]\tLoss: 1.521069\n","Train Epoch: 4 [40960/60000 (68%)]\tLoss: 1.578228\n","Train Epoch: 4 [42240/60000 (70%)]\tLoss: 1.566602\n","Train Epoch: 4 [43520/60000 (72%)]\tLoss: 1.530976\n","Train Epoch: 4 [44800/60000 (75%)]\tLoss: 1.510544\n","Train Epoch: 4 [46080/60000 (77%)]\tLoss: 1.581797\n","Train Epoch: 4 [47360/60000 (79%)]\tLoss: 1.571254\n","Train Epoch: 4 [48640/60000 (81%)]\tLoss: 1.522450\n","Train Epoch: 4 [49920/60000 (83%)]\tLoss: 1.535464\n","Train Epoch: 4 [51200/60000 (85%)]\tLoss: 1.551359\n","Train Epoch: 4 [52480/60000 (87%)]\tLoss: 1.563134\n","Train Epoch: 4 [53760/60000 (90%)]\tLoss: 1.568395\n","Train Epoch: 4 [55040/60000 (92%)]\tLoss: 1.547794\n","Train Epoch: 4 [56320/60000 (94%)]\tLoss: 1.584233\n","Train Epoch: 4 [57600/60000 (96%)]\tLoss: 1.499262\n","Train Epoch: 4 [58880/60000 (98%)]\tLoss: 1.537703\n","Test Set: Average Loss: 0.0015, Accuracy: 9618/10000 (96%)\n","Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.537429\n","Train Epoch: 5 [1280/60000 (2%)]\tLoss: 1.550900\n","Train Epoch: 5 [2560/60000 (4%)]\tLoss: 1.537008\n","Train Epoch: 5 [3840/60000 (6%)]\tLoss: 1.513309\n","Train Epoch: 5 [5120/60000 (9%)]\tLoss: 1.505105\n","Train Epoch: 5 [6400/60000 (11%)]\tLoss: 1.581447\n","Train Epoch: 5 [7680/60000 (13%)]\tLoss: 1.544259\n","Train Epoch: 5 [8960/60000 (15%)]\tLoss: 1.540457\n","Train Epoch: 5 [10240/60000 (17%)]\tLoss: 1.528089\n","Train Epoch: 5 [11520/60000 (19%)]\tLoss: 1.530912\n","Train Epoch: 5 [12800/60000 (21%)]\tLoss: 1.518583\n","Train Epoch: 5 [14080/60000 (23%)]\tLoss: 1.503752\n","Train Epoch: 5 [15360/60000 (26%)]\tLoss: 1.480550\n","Train Epoch: 5 [16640/60000 (28%)]\tLoss: 1.541303\n","Train Epoch: 5 [17920/60000 (30%)]\tLoss: 1.529659\n","Train Epoch: 5 [19200/60000 (32%)]\tLoss: 1.507609\n","Train Epoch: 5 [20480/60000 (34%)]\tLoss: 1.595333\n","Train Epoch: 5 [21760/60000 (36%)]\tLoss: 1.618180\n","Train Epoch: 5 [23040/60000 (38%)]\tLoss: 1.555756\n","Train Epoch: 5 [24320/60000 (41%)]\tLoss: 1.588799\n","Train Epoch: 5 [25600/60000 (43%)]\tLoss: 1.522475\n","Train Epoch: 5 [26880/60000 (45%)]\tLoss: 1.573727\n","Train Epoch: 5 [28160/60000 (47%)]\tLoss: 1.552323\n","Train Epoch: 5 [29440/60000 (49%)]\tLoss: 1.558155\n","Train Epoch: 5 [30720/60000 (51%)]\tLoss: 1.632472\n","Train Epoch: 5 [32000/60000 (53%)]\tLoss: 1.568411\n","Train Epoch: 5 [33280/60000 (55%)]\tLoss: 1.533800\n","Train Epoch: 5 [34560/60000 (58%)]\tLoss: 1.567780\n","Train Epoch: 5 [35840/60000 (60%)]\tLoss: 1.581093\n","Train Epoch: 5 [37120/60000 (62%)]\tLoss: 1.518103\n","Train Epoch: 5 [38400/60000 (64%)]\tLoss: 1.562750\n","Train Epoch: 5 [39680/60000 (66%)]\tLoss: 1.550518\n","Train Epoch: 5 [40960/60000 (68%)]\tLoss: 1.539638\n","Train Epoch: 5 [42240/60000 (70%)]\tLoss: 1.508050\n","Train Epoch: 5 [43520/60000 (72%)]\tLoss: 1.487593\n","Train Epoch: 5 [44800/60000 (75%)]\tLoss: 1.553084\n","Train Epoch: 5 [46080/60000 (77%)]\tLoss: 1.576905\n","Train Epoch: 5 [47360/60000 (79%)]\tLoss: 1.535619\n","Train Epoch: 5 [48640/60000 (81%)]\tLoss: 1.536949\n","Train Epoch: 5 [49920/60000 (83%)]\tLoss: 1.535293\n","Train Epoch: 5 [51200/60000 (85%)]\tLoss: 1.532198\n","Train Epoch: 5 [52480/60000 (87%)]\tLoss: 1.583375\n","Train Epoch: 5 [53760/60000 (90%)]\tLoss: 1.545932\n","Train Epoch: 5 [55040/60000 (92%)]\tLoss: 1.563581\n","Train Epoch: 5 [56320/60000 (94%)]\tLoss: 1.546108\n","Train Epoch: 5 [57600/60000 (96%)]\tLoss: 1.548249\n","Train Epoch: 5 [58880/60000 (98%)]\tLoss: 1.585120\n","Test Set: Average Loss: 0.0015, Accuracy: 9668/10000 (97%)\n","Train Epoch: 6 [0/60000 (0%)]\tLoss: 1.531860\n","Train Epoch: 6 [1280/60000 (2%)]\tLoss: 1.535852\n","Train Epoch: 6 [2560/60000 (4%)]\tLoss: 1.506056\n","Train Epoch: 6 [3840/60000 (6%)]\tLoss: 1.494345\n","Train Epoch: 6 [5120/60000 (9%)]\tLoss: 1.522500\n","Train Epoch: 6 [6400/60000 (11%)]\tLoss: 1.562397\n","Train Epoch: 6 [7680/60000 (13%)]\tLoss: 1.536581\n","Train Epoch: 6 [8960/60000 (15%)]\tLoss: 1.525384\n","Train Epoch: 6 [10240/60000 (17%)]\tLoss: 1.534632\n","Train Epoch: 6 [11520/60000 (19%)]\tLoss: 1.533445\n","Train Epoch: 6 [12800/60000 (21%)]\tLoss: 1.518280\n","Train Epoch: 6 [14080/60000 (23%)]\tLoss: 1.544461\n","Train Epoch: 6 [15360/60000 (26%)]\tLoss: 1.595209\n","Train Epoch: 6 [16640/60000 (28%)]\tLoss: 1.506168\n","Train Epoch: 6 [17920/60000 (30%)]\tLoss: 1.526404\n","Train Epoch: 6 [19200/60000 (32%)]\tLoss: 1.582396\n","Train Epoch: 6 [20480/60000 (34%)]\tLoss: 1.483272\n","Train Epoch: 6 [21760/60000 (36%)]\tLoss: 1.538467\n","Train Epoch: 6 [23040/60000 (38%)]\tLoss: 1.489832\n","Train Epoch: 6 [24320/60000 (41%)]\tLoss: 1.502895\n","Train Epoch: 6 [25600/60000 (43%)]\tLoss: 1.500382\n","Train Epoch: 6 [26880/60000 (45%)]\tLoss: 1.519969\n","Train Epoch: 6 [28160/60000 (47%)]\tLoss: 1.539418\n","Train Epoch: 6 [29440/60000 (49%)]\tLoss: 1.544239\n","Train Epoch: 6 [30720/60000 (51%)]\tLoss: 1.542001\n","Train Epoch: 6 [32000/60000 (53%)]\tLoss: 1.547557\n","Train Epoch: 6 [33280/60000 (55%)]\tLoss: 1.569059\n","Train Epoch: 6 [34560/60000 (58%)]\tLoss: 1.507035\n","Train Epoch: 6 [35840/60000 (60%)]\tLoss: 1.553404\n","Train Epoch: 6 [37120/60000 (62%)]\tLoss: 1.546624\n","Train Epoch: 6 [38400/60000 (64%)]\tLoss: 1.549637\n","Train Epoch: 6 [39680/60000 (66%)]\tLoss: 1.566871\n","Train Epoch: 6 [40960/60000 (68%)]\tLoss: 1.520913\n","Train Epoch: 6 [42240/60000 (70%)]\tLoss: 1.536568\n","Train Epoch: 6 [43520/60000 (72%)]\tLoss: 1.491273\n","Train Epoch: 6 [44800/60000 (75%)]\tLoss: 1.571174\n","Train Epoch: 6 [46080/60000 (77%)]\tLoss: 1.494583\n","Train Epoch: 6 [47360/60000 (79%)]\tLoss: 1.566377\n","Train Epoch: 6 [48640/60000 (81%)]\tLoss: 1.520083\n","Train Epoch: 6 [49920/60000 (83%)]\tLoss: 1.547151\n","Train Epoch: 6 [51200/60000 (85%)]\tLoss: 1.580167\n","Train Epoch: 6 [52480/60000 (87%)]\tLoss: 1.556292\n","Train Epoch: 6 [53760/60000 (90%)]\tLoss: 1.502365\n","Train Epoch: 6 [55040/60000 (92%)]\tLoss: 1.564899\n","Train Epoch: 6 [56320/60000 (94%)]\tLoss: 1.559519\n","Train Epoch: 6 [57600/60000 (96%)]\tLoss: 1.515321\n","Train Epoch: 6 [58880/60000 (98%)]\tLoss: 1.521524\n","Test Set: Average Loss: 0.0015, Accuracy: 9687/10000 (97%)\n","Train Epoch: 7 [0/60000 (0%)]\tLoss: 1.512784\n","Train Epoch: 7 [1280/60000 (2%)]\tLoss: 1.543388\n","Train Epoch: 7 [2560/60000 (4%)]\tLoss: 1.513585\n","Train Epoch: 7 [3840/60000 (6%)]\tLoss: 1.536373\n","Train Epoch: 7 [5120/60000 (9%)]\tLoss: 1.525174\n","Train Epoch: 7 [6400/60000 (11%)]\tLoss: 1.514197\n","Train Epoch: 7 [7680/60000 (13%)]\tLoss: 1.547617\n","Train Epoch: 7 [8960/60000 (15%)]\tLoss: 1.548042\n","Train Epoch: 7 [10240/60000 (17%)]\tLoss: 1.493122\n","Train Epoch: 7 [11520/60000 (19%)]\tLoss: 1.530326\n","Train Epoch: 7 [12800/60000 (21%)]\tLoss: 1.527028\n","Train Epoch: 7 [14080/60000 (23%)]\tLoss: 1.542197\n","Train Epoch: 7 [15360/60000 (26%)]\tLoss: 1.479155\n","Train Epoch: 7 [16640/60000 (28%)]\tLoss: 1.534360\n","Train Epoch: 7 [17920/60000 (30%)]\tLoss: 1.529763\n","Train Epoch: 7 [19200/60000 (32%)]\tLoss: 1.544719\n","Train Epoch: 7 [20480/60000 (34%)]\tLoss: 1.495409\n","Train Epoch: 7 [21760/60000 (36%)]\tLoss: 1.488487\n","Train Epoch: 7 [23040/60000 (38%)]\tLoss: 1.513141\n","Train Epoch: 7 [24320/60000 (41%)]\tLoss: 1.539573\n","Train Epoch: 7 [25600/60000 (43%)]\tLoss: 1.534955\n","Train Epoch: 7 [26880/60000 (45%)]\tLoss: 1.491814\n","Train Epoch: 7 [28160/60000 (47%)]\tLoss: 1.515758\n","Train Epoch: 7 [29440/60000 (49%)]\tLoss: 1.499483\n","Train Epoch: 7 [30720/60000 (51%)]\tLoss: 1.523344\n","Train Epoch: 7 [32000/60000 (53%)]\tLoss: 1.513438\n","Train Epoch: 7 [33280/60000 (55%)]\tLoss: 1.547622\n","Train Epoch: 7 [34560/60000 (58%)]\tLoss: 1.526367\n","Train Epoch: 7 [35840/60000 (60%)]\tLoss: 1.479393\n","Train Epoch: 7 [37120/60000 (62%)]\tLoss: 1.547569\n","Train Epoch: 7 [38400/60000 (64%)]\tLoss: 1.497948\n","Train Epoch: 7 [39680/60000 (66%)]\tLoss: 1.552028\n","Train Epoch: 7 [40960/60000 (68%)]\tLoss: 1.551646\n","Train Epoch: 7 [42240/60000 (70%)]\tLoss: 1.496342\n","Train Epoch: 7 [43520/60000 (72%)]\tLoss: 1.574800\n","Train Epoch: 7 [44800/60000 (75%)]\tLoss: 1.515632\n","Train Epoch: 7 [46080/60000 (77%)]\tLoss: 1.592846\n","Train Epoch: 7 [47360/60000 (79%)]\tLoss: 1.537959\n","Train Epoch: 7 [48640/60000 (81%)]\tLoss: 1.507647\n","Train Epoch: 7 [49920/60000 (83%)]\tLoss: 1.567001\n","Train Epoch: 7 [51200/60000 (85%)]\tLoss: 1.510879\n","Train Epoch: 7 [52480/60000 (87%)]\tLoss: 1.570335\n","Train Epoch: 7 [53760/60000 (90%)]\tLoss: 1.535990\n","Train Epoch: 7 [55040/60000 (92%)]\tLoss: 1.493556\n","Train Epoch: 7 [56320/60000 (94%)]\tLoss: 1.531740\n","Train Epoch: 7 [57600/60000 (96%)]\tLoss: 1.513388\n","Train Epoch: 7 [58880/60000 (98%)]\tLoss: 1.569135\n","Test Set: Average Loss: 0.0015, Accuracy: 9716/10000 (97%)\n","Train Epoch: 8 [0/60000 (0%)]\tLoss: 1.520163\n","Train Epoch: 8 [1280/60000 (2%)]\tLoss: 1.495278\n","Train Epoch: 8 [2560/60000 (4%)]\tLoss: 1.556155\n","Train Epoch: 8 [3840/60000 (6%)]\tLoss: 1.529533\n","Train Epoch: 8 [5120/60000 (9%)]\tLoss: 1.623418\n","Train Epoch: 8 [6400/60000 (11%)]\tLoss: 1.541554\n","Train Epoch: 8 [7680/60000 (13%)]\tLoss: 1.487006\n","Train Epoch: 8 [8960/60000 (15%)]\tLoss: 1.559064\n","Train Epoch: 8 [10240/60000 (17%)]\tLoss: 1.570364\n","Train Epoch: 8 [11520/60000 (19%)]\tLoss: 1.505271\n","Train Epoch: 8 [12800/60000 (21%)]\tLoss: 1.510958\n","Train Epoch: 8 [14080/60000 (23%)]\tLoss: 1.507437\n","Train Epoch: 8 [15360/60000 (26%)]\tLoss: 1.498295\n","Train Epoch: 8 [16640/60000 (28%)]\tLoss: 1.504377\n","Train Epoch: 8 [17920/60000 (30%)]\tLoss: 1.548304\n","Train Epoch: 8 [19200/60000 (32%)]\tLoss: 1.574094\n","Train Epoch: 8 [20480/60000 (34%)]\tLoss: 1.566516\n","Train Epoch: 8 [21760/60000 (36%)]\tLoss: 1.542924\n","Train Epoch: 8 [23040/60000 (38%)]\tLoss: 1.555235\n","Train Epoch: 8 [24320/60000 (41%)]\tLoss: 1.537431\n","Train Epoch: 8 [25600/60000 (43%)]\tLoss: 1.532772\n","Train Epoch: 8 [26880/60000 (45%)]\tLoss: 1.583671\n","Train Epoch: 8 [28160/60000 (47%)]\tLoss: 1.487161\n","Train Epoch: 8 [29440/60000 (49%)]\tLoss: 1.476297\n","Train Epoch: 8 [30720/60000 (51%)]\tLoss: 1.501193\n","Train Epoch: 8 [32000/60000 (53%)]\tLoss: 1.521474\n","Train Epoch: 8 [33280/60000 (55%)]\tLoss: 1.509612\n","Train Epoch: 8 [34560/60000 (58%)]\tLoss: 1.496038\n","Train Epoch: 8 [35840/60000 (60%)]\tLoss: 1.498853\n","Train Epoch: 8 [37120/60000 (62%)]\tLoss: 1.494267\n","Train Epoch: 8 [38400/60000 (64%)]\tLoss: 1.540895\n","Train Epoch: 8 [39680/60000 (66%)]\tLoss: 1.523707\n","Train Epoch: 8 [40960/60000 (68%)]\tLoss: 1.478961\n","Train Epoch: 8 [42240/60000 (70%)]\tLoss: 1.522607\n","Train Epoch: 8 [43520/60000 (72%)]\tLoss: 1.562666\n","Train Epoch: 8 [44800/60000 (75%)]\tLoss: 1.520720\n","Train Epoch: 8 [46080/60000 (77%)]\tLoss: 1.510141\n","Train Epoch: 8 [47360/60000 (79%)]\tLoss: 1.531605\n","Train Epoch: 8 [48640/60000 (81%)]\tLoss: 1.526727\n","Train Epoch: 8 [49920/60000 (83%)]\tLoss: 1.522202\n","Train Epoch: 8 [51200/60000 (85%)]\tLoss: 1.525984\n","Train Epoch: 8 [52480/60000 (87%)]\tLoss: 1.559648\n","Train Epoch: 8 [53760/60000 (90%)]\tLoss: 1.490559\n","Train Epoch: 8 [55040/60000 (92%)]\tLoss: 1.469467\n","Train Epoch: 8 [56320/60000 (94%)]\tLoss: 1.541070\n","Train Epoch: 8 [57600/60000 (96%)]\tLoss: 1.568617\n","Train Epoch: 8 [58880/60000 (98%)]\tLoss: 1.512804\n","Test Set: Average Loss: 0.0015, Accuracy: 9738/10000 (97%)\n","Train Epoch: 9 [0/60000 (0%)]\tLoss: 1.499225\n","Train Epoch: 9 [1280/60000 (2%)]\tLoss: 1.507430\n","Train Epoch: 9 [2560/60000 (4%)]\tLoss: 1.549425\n","Train Epoch: 9 [3840/60000 (6%)]\tLoss: 1.482681\n","Train Epoch: 9 [5120/60000 (9%)]\tLoss: 1.535570\n","Train Epoch: 9 [6400/60000 (11%)]\tLoss: 1.517074\n","Train Epoch: 9 [7680/60000 (13%)]\tLoss: 1.489686\n","Train Epoch: 9 [8960/60000 (15%)]\tLoss: 1.512745\n","Train Epoch: 9 [10240/60000 (17%)]\tLoss: 1.477851\n","Train Epoch: 9 [11520/60000 (19%)]\tLoss: 1.547367\n","Train Epoch: 9 [12800/60000 (21%)]\tLoss: 1.539161\n","Train Epoch: 9 [14080/60000 (23%)]\tLoss: 1.532467\n","Train Epoch: 9 [15360/60000 (26%)]\tLoss: 1.524710\n","Train Epoch: 9 [16640/60000 (28%)]\tLoss: 1.493917\n","Train Epoch: 9 [17920/60000 (30%)]\tLoss: 1.539510\n","Train Epoch: 9 [19200/60000 (32%)]\tLoss: 1.557424\n","Train Epoch: 9 [20480/60000 (34%)]\tLoss: 1.550107\n","Train Epoch: 9 [21760/60000 (36%)]\tLoss: 1.504534\n","Train Epoch: 9 [23040/60000 (38%)]\tLoss: 1.501234\n","Train Epoch: 9 [24320/60000 (41%)]\tLoss: 1.522175\n","Train Epoch: 9 [25600/60000 (43%)]\tLoss: 1.547280\n","Train Epoch: 9 [26880/60000 (45%)]\tLoss: 1.531128\n","Train Epoch: 9 [28160/60000 (47%)]\tLoss: 1.543233\n","Train Epoch: 9 [29440/60000 (49%)]\tLoss: 1.508387\n","Train Epoch: 9 [30720/60000 (51%)]\tLoss: 1.586971\n","Train Epoch: 9 [32000/60000 (53%)]\tLoss: 1.496309\n","Train Epoch: 9 [33280/60000 (55%)]\tLoss: 1.477533\n","Train Epoch: 9 [34560/60000 (58%)]\tLoss: 1.500285\n","Train Epoch: 9 [35840/60000 (60%)]\tLoss: 1.541486\n","Train Epoch: 9 [37120/60000 (62%)]\tLoss: 1.524760\n","Train Epoch: 9 [38400/60000 (64%)]\tLoss: 1.547722\n","Train Epoch: 9 [39680/60000 (66%)]\tLoss: 1.520199\n","Train Epoch: 9 [40960/60000 (68%)]\tLoss: 1.502910\n","Train Epoch: 9 [42240/60000 (70%)]\tLoss: 1.525847\n","Train Epoch: 9 [43520/60000 (72%)]\tLoss: 1.510984\n","Train Epoch: 9 [44800/60000 (75%)]\tLoss: 1.542926\n","Train Epoch: 9 [46080/60000 (77%)]\tLoss: 1.533447\n","Train Epoch: 9 [47360/60000 (79%)]\tLoss: 1.543205\n","Train Epoch: 9 [48640/60000 (81%)]\tLoss: 1.518801\n","Train Epoch: 9 [49920/60000 (83%)]\tLoss: 1.505969\n","Train Epoch: 9 [51200/60000 (85%)]\tLoss: 1.522093\n","Train Epoch: 9 [52480/60000 (87%)]\tLoss: 1.530467\n","Train Epoch: 9 [53760/60000 (90%)]\tLoss: 1.522697\n","Train Epoch: 9 [55040/60000 (92%)]\tLoss: 1.509841\n","Train Epoch: 9 [56320/60000 (94%)]\tLoss: 1.477410\n","Train Epoch: 9 [57600/60000 (96%)]\tLoss: 1.525958\n","Train Epoch: 9 [58880/60000 (98%)]\tLoss: 1.520255\n","Test Set: Average Loss: 0.0015, Accuracy: 9764/10000 (98%)\n","Train Epoch: 10 [0/60000 (0%)]\tLoss: 1.493133\n","Train Epoch: 10 [1280/60000 (2%)]\tLoss: 1.534541\n","Train Epoch: 10 [2560/60000 (4%)]\tLoss: 1.524509\n","Train Epoch: 10 [3840/60000 (6%)]\tLoss: 1.514043\n","Train Epoch: 10 [5120/60000 (9%)]\tLoss: 1.508286\n","Train Epoch: 10 [6400/60000 (11%)]\tLoss: 1.512269\n","Train Epoch: 10 [7680/60000 (13%)]\tLoss: 1.592609\n","Train Epoch: 10 [8960/60000 (15%)]\tLoss: 1.528012\n","Train Epoch: 10 [10240/60000 (17%)]\tLoss: 1.488883\n","Train Epoch: 10 [11520/60000 (19%)]\tLoss: 1.514847\n","Train Epoch: 10 [12800/60000 (21%)]\tLoss: 1.528945\n","Train Epoch: 10 [14080/60000 (23%)]\tLoss: 1.504113\n","Train Epoch: 10 [15360/60000 (26%)]\tLoss: 1.508081\n","Train Epoch: 10 [16640/60000 (28%)]\tLoss: 1.505776\n","Train Epoch: 10 [17920/60000 (30%)]\tLoss: 1.525377\n","Train Epoch: 10 [19200/60000 (32%)]\tLoss: 1.538610\n","Train Epoch: 10 [20480/60000 (34%)]\tLoss: 1.535929\n","Train Epoch: 10 [21760/60000 (36%)]\tLoss: 1.507074\n","Train Epoch: 10 [23040/60000 (38%)]\tLoss: 1.515217\n","Train Epoch: 10 [24320/60000 (41%)]\tLoss: 1.499714\n","Train Epoch: 10 [25600/60000 (43%)]\tLoss: 1.525709\n","Train Epoch: 10 [26880/60000 (45%)]\tLoss: 1.528603\n","Train Epoch: 10 [28160/60000 (47%)]\tLoss: 1.504205\n","Train Epoch: 10 [29440/60000 (49%)]\tLoss: 1.492644\n","Train Epoch: 10 [30720/60000 (51%)]\tLoss: 1.591874\n","Train Epoch: 10 [32000/60000 (53%)]\tLoss: 1.507586\n","Train Epoch: 10 [33280/60000 (55%)]\tLoss: 1.561789\n","Train Epoch: 10 [34560/60000 (58%)]\tLoss: 1.520687\n","Train Epoch: 10 [35840/60000 (60%)]\tLoss: 1.519538\n","Train Epoch: 10 [37120/60000 (62%)]\tLoss: 1.524528\n","Train Epoch: 10 [38400/60000 (64%)]\tLoss: 1.531024\n","Train Epoch: 10 [39680/60000 (66%)]\tLoss: 1.536158\n","Train Epoch: 10 [40960/60000 (68%)]\tLoss: 1.561334\n","Train Epoch: 10 [42240/60000 (70%)]\tLoss: 1.538089\n","Train Epoch: 10 [43520/60000 (72%)]\tLoss: 1.499246\n","Train Epoch: 10 [44800/60000 (75%)]\tLoss: 1.531210\n","Train Epoch: 10 [46080/60000 (77%)]\tLoss: 1.492254\n","Train Epoch: 10 [47360/60000 (79%)]\tLoss: 1.573280\n","Train Epoch: 10 [48640/60000 (81%)]\tLoss: 1.503574\n","Train Epoch: 10 [49920/60000 (83%)]\tLoss: 1.494313\n","Train Epoch: 10 [51200/60000 (85%)]\tLoss: 1.515921\n","Train Epoch: 10 [52480/60000 (87%)]\tLoss: 1.551172\n","Train Epoch: 10 [53760/60000 (90%)]\tLoss: 1.550611\n","Train Epoch: 10 [55040/60000 (92%)]\tLoss: 1.522723\n","Train Epoch: 10 [56320/60000 (94%)]\tLoss: 1.544481\n","Train Epoch: 10 [57600/60000 (96%)]\tLoss: 1.553449\n","Train Epoch: 10 [58880/60000 (98%)]\tLoss: 1.492292\n","Test Set: Average Loss: 0.0015, Accuracy: 9742/10000 (97%)\n"]}]}]}